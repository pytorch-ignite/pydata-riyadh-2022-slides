<!doctype html><html lang=en><head><meta charset=utf-8><title>PyTorch-Ignite: train and evaluate neural networks flexibly and transparently</title><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="black-translucent"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><link rel=stylesheet href=/pydata-riyadh-2022-slides/reveal-js/css/reset.css><link rel=stylesheet href=/pydata-riyadh-2022-slides/reveal-js/css/reveal.css><link rel=stylesheet href=/pydata-riyadh-2022-slides/_.min.92f64515320309568348a63a98095e2ea25df2bc674d324a1f8ab400c2feb87a.css id=theme><link rel=stylesheet href=/pydata-riyadh-2022-slides/highlight-js/monokai-sublime.min.css></head><body><style>#logo{position:absolute;top:1%;left:1%;width:15%}</style><img id=logo src=https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logomark.svg alt><div class=reveal><div class=slides><section><h1 id=pydata-riyadh-sprint>PyData Riyadh Sprint</h1><h2 id=pytorch-ignite>PyTorch-Ignite</h2><blockquote><p>High-level library to help with training and evaluating neural networks in PyTorch flexibly and transparently.</p></blockquote><div class=container><div class=columns><div class=column><div class=level-left><a class=level-item href=https://www.github.com/pytorch/ignite><span class=icon><i class="fab fa-github"></i></span></a><a class=level-item href=https://www.twitter.com/pytorch_ignite><span class=icon><i class="fab fa-twitter"></i></span></a><a class=level-item href=https://www.facebook.com/PyTorch-Ignite-Community-105837321694508><span class=icon><i class="fab fa-facebook"></i></span></a><a class=level-item href=https://dev.to/pytorch-ignite><span class=icon><i class="fab fa-dev"></i></span></a><a class=level-item href=https://discord.gg/djZtm3EmKj><span class=icon><i class="fab fa-discord"></i></span></a></div></div></div></div><div style=color:transparent>.</div><div class=center><pre><code class=language-python>if __name__ == &quot;__main__&quot;:
    print(&quot;Let's have fun helping PyTorch-Ignite open source project !&quot;)
</code></pre></div><div style=color:transparent>.</div><p>Slides: <a href=https://pytorch-ignite.github.io/pydata-riyadh-2022-slides/>https://pytorch-ignite.github.io/pydata-riyadh-2022-slides/</a></p></section><section><h2 id=maintainers-leading-the-sprint>Maintainers leading the sprint</h2><table class=center><tr><td><img width=80 src="https://avatars.githubusercontent.com/u/13217677?v=4"></td><td>Priyansi <a href=https://github.com/Priyansi>@Priyansi</a></td><td style=font-size:20px>A CS Undergrad. Currently working on the docs of PyTorch-Ignite<p>and helping manage the community</p></td></tr><tr><td><img width=80 src="https://avatars.githubusercontent.com/u/2459423?v=4"></td><td>Victor <a href=https://github.com/vfdev-5>@vfdev-5</a></td><td style=font-size:20px>Software Engineer at <a href=https://www.quansight.com/>Quansight</a> working on AI-related open source projects</td></tr><tr><td><img width=80 src="https://avatars.githubusercontent.com/u/20302007?v=4"></td><td>Fran√ßois <a href=https://github.com/fco-dv>@fco-dv</a></td><td style=font-size:20px>Software Engineer at <a href=https://www.ifpenergiesnouvelles.com/>IFPEN</a></td></tr></table></section><section><h1 id=content>Content</h1><ol><li>About the <em>PyTorch-Ignite</em> project</li><li>What are <em>PyTorch</em> and <em>PyTorch-Ignite</em> ?</li><li>Quick-start <em>PyTorch-Ignite</em> example</li><li>How you can help ?</li></ol></section><section><section data-shortcode-section><h1 id=about-pytorch-ignite-project>About &ldquo;PyTorch-Ignite&rdquo; project</h1><p>Community-driven open source and <em>NumFOCUS Affiliated</em> Project</p><p>maintained by volunteers in the PyTorch community:</p><pre><code>@vfdev-5, @ydcjeff, @KickItLikeShika, @sdesrozis, @alykhantejani, @anmolsjoshi,
@trsvchn, @fco-dv, @Priyansi, @Moh-Yakoub, @gucifer, @Ishan-Kumar2 ...
</code></pre><p><img src=https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f389@2x.png alt=o1>
<img src=https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f44f@2x.png alt=o2>
<img src=https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f64f@2x.png alt=o3></p><p>With the support of:</p><img width=150 src=https://numfocus.org/wp-content/uploads/2017/07/NumFocus_LRG.png>
<img width=150 src=https://raw.githubusercontent.com/Quansight-Labs/quansight-labs-site/master/files/images/QuansightLabs_logo_V2.png>
<img width=150 src=https://raw.githubusercontent.com/pytorch-ignite/pytorch-ignite.ai/main/static/_images/ifpen.png>
<img width=80 src=https://d1.awsstatic.com/logos/aws-logo/full-color/AWS-Logo_Full-Color_1000x600.23165eb2b9af9cc8e068e74fbabc28222d091298.png>
<img width=150 src=https://raw.githubusercontent.com/pytorch-ignite/pytorch-ignite.ai/main/static/_images/agenium_space.png></section><section><h1 id=community-engagement>Community Engagement</h1><div style=font-size:24px><ul><li><p>Google Summer of Code 2021</p><ul><li>Mentored two great students (<em>Ahmed</em> and <em>Arpan</em>)</li></ul></li><li><p>Google Season of Docs 2021</p><ul><li>Worked with great tech writer (<em>Priyansi</em>)</li></ul></li><li><p>Hacktoberfest 2020 and 2021</p></li><li><p><strong>PyData Global Mentored Sprint 2020 and 2021</strong></p></li><li><p>Public meetings on Discord, open to everyone</p></li></ul><p><em>Stay tuned for upcoming events &mldr;</em></p><img width=250 src=https://summerofcode.withgoogle.com/assets/media/logo.svg>
<img width=50 src=https://developers.google.com/season-of-docs/images/SeasonofDocs_Icon_Grey_300ppi_trimmed_480.png>
<img width=50 src=https://hacktoberfestswaglist.com/img/Hacktoberfest_21.jpg>
<img width=150 src=https://pydata.org/global2021/wp-content/uploads/2021/06/logo.png></div></section></section><section><section data-shortcode-section><h1 id=pytorch-in-a-nutshell>PyTorch in a nutshell</h1><table style=font-size:20px><tr><td><pre><code class=language-python>import torch
import torch.nn as nn

device = &quot;cuda&quot;

class MyNN(nn.Module):
    def __init__(self):
        super(MyNN, self).__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = MyNN().to(device)
</code></pre></td><td><div style=color:transparent>.</div><ul><li>tensor manipulations (device: CPUs, GPUs, TPUs)</li><li>NN components, optimizers, loss functions</li><li>Distributed computations</li><li>Profiling</li><li>other cool features &mldr;</li><li>Domain libraries: vision, text, audio</li><li>Rich ecosystem</li></ul></td></tr></table><p><a href=https://pytorch.org/tutorials/beginner/basics/intro.html>https://pytorch.org/tutorials/beginner/basics/intro.html</a></p></section><section><h1 id=quick-start-ml-with-pytorch>Quick-start ML with PyTorch</h1><div style=font-size:20px><p><a href=https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html>Computer Vision example with Fashion MNIST</a></p><p>Problem: 1 - how to classify images ?</p><p><code>model(image) -> predicted label</code></p><p>2 - How measure model performances ?</p><p><code>predicted labels vs correct labels</code></p><p><img height=300 src=https://image.itmedia.co.jp/ait/articles/2005/28/di-01.gif></p></section><section><h1 id=quick-start-ml-with-pytorch-1>Quick-start ML with PyTorch</h1><div style=font-size:20px><ul><li>Setup training and testing data</li></ul><pre><code class=language-python>from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor, Lambda, Compose

# Setup training/test data
training_data = datasets.FashionMNIST(root=&quot;data&quot;, train=True, download=True, transform=ToTensor())
test_data = datasets.FashionMNIST(root=&quot;data&quot;, train=False, transform=ToTensor())

batch_size = 64

# Create data loaders
train_dataloader = DataLoader(training_data, batch_size=batch_size)
test_dataloader = DataLoader(test_data, batch_size=batch_size)

# Optionally, for debugging:
for X, y in test_dataloader:
    print(&quot;Shape of X [N, C, H, W]: &quot;, X.shape)
    print(&quot;Shape of y: &quot;, y.shape, y.dtype)
    break

# Output:
# Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])
# Shape of y:  torch.Size([64]) torch.int64
</code></pre></div></section><section><h1 id=quick-start-ml-with-pytorch-2>Quick-start ML with PyTorch</h1><div style=font-size:20px><ul><li>Create a model</li></ul><pre><code class=language-python>import torch
from torch import nn

device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.flatten = nn.Flatten()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(28*28, 512),
            nn.ReLU(),
            nn.Linear(512, 512),
            nn.ReLU(),
            nn.Linear(512, 10)
        )

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear_relu_stack(x)
        return logits

model = NeuralNetwork().to(device)
</code></pre></div></section><section><h1 id=quick-start-ml-with-pytorch-3>Quick-start ML with PyTorch</h1><div style=font-size:20px><ul><li>Model training<ul><li>Loss function: cross-entropy</li><li>Optimization with Stochastic Gradient Descent</li></ul></li></ul><pre><code class=language-python>loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)

def train(dataloader, model, loss_fn, optimizer):
    model.train()
    for X, y in dataloader:
        X, y = X.to(device), y.to(device)
        pred = model(X)
        loss = loss_fn(pred, y)

        # Backpropagation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

def test(dataloader, model, loss_fn):
    # code to compute and print average loss and accuracy

epochs = 5
for t in range(epochs):
    print(f&quot;Epoch {t+1}\n-------------------------------&quot;)
    train(train_dataloader, model, loss_fn, optimizer)
    test(test_dataloader, model, loss_fn)
print(&quot;Done!&quot;)
</code></pre></div></section><section><h2 id=why-using-pytorch-without-ignite-is-suboptimal->Why using PyTorch without Ignite is suboptimal ?</h2><p>For NN training and evaluation:</p><ul><li>PyTorch gives only &ldquo;low&rdquo;-level building components</li><li>Common bricks to code in any user project:<ul><li>metrics</li><li>checkpointing, best model saving, early stopping, &mldr;</li><li>logging to experiment tracking systems</li><li>code adaptation for device (e.g. GPU, XLA)</li></ul></li></ul></section><section><ul><li>Pure PyTorch code</li></ul><div style=font-size:20px><pre><code class=language-python>
model = Net()
train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)
optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.8)
criterion = torch.nn.NLLLoss()

max_epochs = 10
validate_every = 100
checkpoint_every = 100


def validate(model, val_loader):
    model = model.eval()
    num_correct = 0
    num_examples = 0
    for batch in val_loader:
        input, target = batch
        output = model(input)
        correct = torch.eq(torch.round(output).type(target.type()), target).view(-1)
        num_correct += torch.sum(correct).item()
        num_examples += correct.shape[0]
    return num_correct / num_examples


def checkpoint(model, optimizer, checkpoint_dir):
    # ...

def save_best_model(model, current_accuracy, best_accuracy):
    # ...

iteration = 0
best_accuracy = 0.0

for epoch in range(max_epochs):
    for batch in train_loader:
        model = model.train()
        optimizer.zero_grad()
        input, target = batch
        output = model(input)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        if iteration % validate_every == 0:
            binary_accuracy = validate(model, val_loader)
            print(&quot;After {} iterations, binary accuracy = {:.2f}&quot;
                  .format(iteration, binary_accuracy))
            save_best_model(model, binary_accuracy, best_accuracy)

        if iteration % checkpoint_every == 0:
            checkpoint(model, optimizer, checkpoint_dir)
        iteration += 1

</code></pre></div></section><section><h1 id=pytorch-ignite-what-and-why->PyTorch-Ignite: what and why? ü§î</h1><blockquote><p>High-level <strong>library</strong> to help with training and evaluating neural networks in PyTorch flexibly and transparently.</p></blockquote><ul><li><a href=https://github.com/pytorch/ignite>https://github.com/pytorch/ignite</a></li></ul><table style=font-size:20px><tr><td><pre><code class=language-python>
def train_step(engine, batch):
  #  ... any training logic ...
  return batch_loss

trainer = Engine(train_step)

# Compose your pipeline ...

trainer.run(train_loader, max_epochs=100)


</code></pre></td><td><pre><code class=language-python>
metrics = {
  &quot;precision&quot;: Precision(),
  &quot;recall&quot;: Recall()
}

evaluator = create_supervised_evaluator(
  model,
  metrics=metrics
)


</code></pre></td><td><pre><code class=language-python>@trainer.on(Events.EPOCH_COMPLETED)
def run_evaluation():
  evaluator.run(test_loader)

handler = ModelCheckpoint(
  '/tmp/models', 'checkpoint'
)
trainer.add_event_handler(
  Events.EPOCH_COMPLETED,
  handler,
  {'model': model}
)
</code></pre></td></tr></table></section><section><h1 id=key-concepts-in-a-nutshell>Key concepts in a nutshell</h1><h4 id=pytorch-ignite-is-about>PyTorch-Ignite is about:</h4><ol><li>Engine and Event System</li><li>Out-of-the-box metrics to easily evaluate models</li><li>Built-in handlers to compose training pipeline</li><li>Distributed Training support</li></ol></section><section><h1 id=what-makes-pytorch-ignite-unique->What makes PyTorch-Ignite unique ?</h1><ul><li>Composable and interoperable components</li><li>Simple and understandable code</li><li>Open-source community involvement</li></ul></section><section><h1 id=how-pytorch-ignite-makes-users-live-easier->How PyTorch-Ignite makes user&rsquo;s live easier ?</h1><p>With PyTorch-Ignite:</p><ul><li>Less code than pure PyTorch while ensuring maximum control and simplicity</li><li>Easily get more refactored and structured code</li><li>Extensible API for metrics, experiment managers, and other components</li><li>Same code for non-distributed and distributed configs</li></ul></section></section><section><section data-shortcode-section><h1 id=quick-start-pytorch-ignite-example->Quick-start PyTorch-Ignite example üë©‚Äçüíªüë®‚Äçüíª</h1><p>Let&rsquo;s train a MNIST classifier with PyTorch-Ignite!</p><div style=color:transparent>.</div><p><a href=https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/>https://pytorch-ignite.ai/tutorials/beginner/01-getting-started/</a></p></section><section><p>Any questions before we go on ?</p></section></section><section><section data-shortcode-section><h1 id=how-you-can-help->How you can help ?</h1><p>Participating GitHub repositories:</p><ul><li><p>‚û°Ô∏è <a href=https://github.com/pytorch/ignite>PyTorch-Ignite</a> - Library to help with training and evaluating neural networks</p></li><li><p><a href=https://github.com/pytorch-ignite/examples>PyTorch-Ignite Examples repository</a> - Examples, tutorials, and how-to guides</p></li></ul></section><section><h1 id=prerequisites>Prerequisites</h1><ul><li>Basic Python knowledge</li><li>Basic PyTorch knowledge</li><li>Basic Machine Learning knowledge</li></ul></section><section><h1 id=start-contributing>Start contributing</h1><h2 id=codebase-structure>Codebase structure</h2><div style=font-size:20px><ul><li><a href=ignite>ignite</a> - Core library files<ul><li><a href=ignite/engine>engine</a> - Module containing core classes like Engine, Events, State.</li><li><a href=ignite/handlers>handlers</a> - Module containing out-of-the-box handlers</li><li><a href=ignite/metrics>metrics</a> - Module containing out-of-the-box metrics</li><li><a href=ignite/contrib>contrib</a> - Contrib module with other metrics, handlers classes that may require additional dependencies</li><li><a href=ignite/distributed>distributed</a> - Module with helpers for distributed computations</li></ul></li><li><a href=tests>tests</a> - Python unit tests</li><li><a href=docs>docs</a> - Documentation files</li></ul></div><p><a href=https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md#developing-ignite>https://github.com/pytorch/ignite/blob/master/CONTRIBUTING.md#developing-ignite</a></p></section><section><h1 id=help-wanted-issues>Help-wanted issues:</h1><p><a href="https://github.com/pytorch/ignite/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22">https://github.com/pytorch/ignite/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22</a></p></section></section><section><section data-shortcode-section><h1 id=how-you-can-help->How you can help ?</h1><p>Participating GitHub repositories:</p><ul><li><p><a href=https://github.com/pytorch/ignite>PyTorch-Ignite</a> - Library to help with training and evaluating neural networks</p></li><li><p>‚û°Ô∏è <a href=https://github.com/pytorch-ignite/examples>PyTorch-Ignite Examples repository</a> - Examples, tutorials, and how-to guides</p></li></ul></section><section><h1 id=prerequisites>Prerequisites</h1><ul><li>Basic Machine/Deep Learning knowledge</li><li>Basic PyTorch and PyTorch-Ignite knowledge</li></ul></section><section><h1 id=start-contributing-12>Start contributing (1/2)</h1><p><strong>Your feedback is valuable!</strong></p><ul><li>Check out our new site: <a href=https://pytorch-ignite.ai/>https://pytorch-ignite.ai/</a></li><li>Open an issue if see a typo, something is not clear, etc<ul><li><a href=https://github.com/pytorch-ignite/examples/issues>https://github.com/pytorch-ignite/examples/issues</a></li><li><a href=https://github.com/pytorch-ignite/pytorch-ignite.ai/issues>https://github.com/pytorch-ignite/pytorch-ignite.ai/issues</a></li></ul></li></ul></section><section><h1 id=start-contributing-22>Start contributing (2/2)</h1><h2 id=contributing-guidelines>Contributing guidelines:</h2><ul><li>Setup Jupyter Lab/Notebook with PyTorch and PyTorch-Ignite installed<ul><li><a href=https://pytorch.org/get-started/locally/>https://pytorch.org/get-started/locally/</a></li><li><code>pip install pytorch-ignite</code></li></ul></li></ul><div style=color:transparent>.</div><h2 id=help-wanted-issues>Help-wanted issues:</h2><ul><li><a href="https://github.com/pytorch-ignite/examples/issues?q=is%3Aissue+is%3Aopen+label%3APyDataGlobal2021">https://github.com/pytorch-ignite/examples/issues?q=is%3Aissue+is%3Aopen+label%3APyDataGlobal2021</a></li></ul></section></section><section><table><tr><td><h2 id=thank-you-for-participating>Thank you for participating</h2><h2 id=in-this-sprint-session->in this sprint session !</h2></td><td style="border:1px solid #000"><p>Follow us on</p><a class=level-item href=https://www.twitter.com/pytorch_ignite><span class=icon><i class="fab fa-twitter"></i></span></a><a class=level-item href=https://www.facebook.com/PyTorch-Ignite-Community-105837321694508><span class=icon><i class="fab fa-facebook"></i></span></a><a class=level-item href=https://dev.to/pytorch-ignite><span class=icon><i class="fab fa-dev"></i></span></a><p>and check out our new website:</p><p><a href=https://pytorch-ignite.ai>https://pytorch-ignite.ai</a></p></td></tr></table><div style=color:transparent>.</div><p>We are looking for contributors to help out with the project.</p><p><img src=https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-small/1f3c5@2x.png alt=o1>
Everyone is welcome to contribute
<img src=https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-small/1f4af@2x.png alt=o2></p><a class=level-item href=https://www.github.com/pytorch/ignite><span class=icon><i class="fab fa-github"></i></span></a><a class=level-item href=https://discord.gg/djZtm3EmKj><span class=icon><i class="fab fa-discord"></i></span></a><div style=color:transparent>.</div></section><section><section data-shortcode-section><h1 id=the-big-picture>The Big Picture</h1><img height=500 src=images/Ignite_Big_Picture.png></section><section><h2 id=engine-and-event-system>Engine and Event System</h2><table style=font-size:20px><tr><td><div style=color:transparent>.</div><ul><li><p><strong>Engine</strong></p><ul><li>Loops on user data</li><li>Applies an arbitrary user function on batches</li></ul></li><li><p><strong>Event system</strong></p><ul><li>Customizable event collections</li><li>Triggers handlers attached to events</li></ul></li></ul></td><td>In its simpliest form:<pre><code class=language-python data-line-numbers=2,5,7|1,3,6,8,10,11>fire_event(Events.STARTED)
while epoch &lt; max_epochs:
    fire_event(Events.EPOCH_STARTED)

    for batch in data:
        fire_event(Events.ITERATION_STARTED)
        output = train_step(batch)
        fire_event(Events.ITERATION_COMPLETED)

    fire_event(Events.EPOCH_COMPLETED)
fire_event(Events.COMPLETED)
</code></pre></td></tr></table></section><section><h3 id=simplified-training-and-validation-loop>Simplified training and validation loop</h3><div style=font-size:20px><p>No more coding <code>for/while</code> loops on epochs and iterations. Users instantiate engines and run them.</p><pre><code class=language-python>from ignite.engine import Engine, Events, create_supervised_evaluator
from ignite.metrics import Accuracy


# Setup training engine:
def train_step(engine, batch):
    # Users can do whatever they need on a single iteration
    # Eg. forward/backward pass for any number of models, optimizers, etc.
    # ...

trainer = Engine(train_step)

# Setup single model evaluation engine
evaluator = create_supervised_evaluator(model, metrics={&quot;accuracy&quot;: Accuracy()})

def validation():
    state = evaluator.run(validation_data_loader)
    # print computed metrics
    print(trainer.state.epoch, state.metrics)

# Run model's validation at the end of each epoch
trainer.add_event_handler(Events.EPOCH_COMPLETED, validation)

# Start the training
trainer.run(training_data_loader, max_epochs=100)
</code></pre></div></section><section><h3 id=power-of-events--handlers->Power of Events & Handlers üöÄ</h3><h4 id=1-execute-any-number-of-functions-whenever-you-wish>1. Execute any number of functions whenever you wish</h4><div style=font-size:20px><p>Handlers can be any function: e.g. lambda, simple function, class method, etc.</p><pre><code class=language-python>trainer.add_event_handler(Events.STARTED, lambda _: print(&quot;Start training&quot;))

# attach handler with args, kwargs
mydata = [1, 2, 3, 4]
logger = ...

def on_training_ended(data):
    print(f&quot;Training is ended. mydata={data}&quot;)
    # User can use variables from another scope
    logger.info(&quot;Training is ended&quot;)


trainer.add_event_handler(Events.COMPLETED, on_training_ended, mydata)
# call any number of functions on a single event
trainer.add_event_handler(Events.COMPLETED, lambda engine: print(engine.state.times))

@trainer.on(Events.ITERATION_COMPLETED)
def log_something(engine):
    print(engine.state.output)
</code></pre></div></section><section><h3 id=power-of-events--handlers>Power of Events & Handlers</h3><h4 id=2-built-in-events-filtering-and-stacking>2. Built-in events filtering and stacking</h4><div style=font-size:20px><pre><code class=language-python># run the validation every 5 epochs
@trainer.on(Events.EPOCH_COMPLETED(every=5))
def run_validation():
    # run validation

@trainer.on(Events.COMPLETED | Events.EPOCH_COMPLETED(every=10))
def run_another_validation():
    # ...

# change some training variable once on 20th epoch
@trainer.on(Events.EPOCH_STARTED(once=20))
def change_training_variable():
    # ...

# Trigger handler with customly defined frequency
@trainer.on(Events.ITERATION_COMPLETED(event_filter=first_x_iters))
def log_gradients():
    # ...

</code></pre></div></section><section><h3 id=power-of-events--handlers-1>Power of Events & Handlers</h3><h4 id=3-custom-events-to-go-beyond-standard-events>3. Custom events to go beyond standard events</h4><div style=font-size:20px><pre><code class=language-python>from ignite.engine import EventEnum

# Define custom events
class BackpropEvents(EventEnum):
    BACKWARD_STARTED = 'backward_started'
    BACKWARD_COMPLETED = 'backward_completed'
    OPTIM_STEP_COMPLETED = 'optim_step_completed'

def train_step(engine, batch):
    # ...
    loss = criterion(y_pred, y)
    engine.fire_event(BackpropEvents.BACKWARD_STARTED)
    loss.backward()
    engine.fire_event(BackpropEvents.BACKWARD_COMPLETED)
    optimizer.step()
    engine.fire_event(BackpropEvents.OPTIM_STEP_COMPLETED)
    # ...

trainer = Engine(train_step)
trainer.register_events(*BackpropEvents)

@trainer.on(BackpropEvents.BACKWARD_STARTED)
def function_before_backprop(engine):
    # ...
</code></pre></div></section><section><h1 id=out-of-the-box-metrics->Out-of-the-box metrics üìà</h1><p>50+ distributed ready out-of-the-box metrics to easily evaluate models.</p><ul><li>Dedicated to many Deep Learning tasks</li><li>Easily composable to assemble a custom metric</li><li>Easily extendable to create custom metrics</li></ul><div style=color:transparent>.</div><pre><code class=language-python>precision = Precision(average=False)
recall = Recall(average=False)
F1_per_class = (precision * recall * 2 / (precision + recall))
F1_mean = F1_per_class.mean()  # torch mean method
F1_mean.attach(engine, &quot;F1&quot;)
</code></pre></section><section><h1 id=built-in-handlers>Built-in Handlers</h1><table style=font-size:20px><tr><td><div style=color:transparent>.</div><ul><li>Logging to experiment tracking systems</li><li>Checkpointing,</li><li>Early stopping</li><li>Profiling</li><li>Parameter scheduling</li><li>etc.</li></ul></td><td><pre><code class=language-python># model checkpoint handler
checkpoint = ModelCheckpoint('/tmp/ckpts', 'training')
trainer.add_event_handler(Events.EPOCH_COMPLETED(every=2), handler, {'model': model})

# early stopping handler
def score_function(engine):
    val_loss = engine.state.metrics['acc']
    return val_loss
es = EarlyStopping(3, score_function, trainer)
evaluator.add_event_handler(Events.COMPLETED, handler)

# Piecewise linear parameter scheduler
scheduler = PiecewiseLinear(optimizer, 'lr', [(10, 0.5), (20, 0.45), (21, 0.3), (30, 0.1), (40, 0.1)])
trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)

# TensorBoard logger: batch loss, metrics
tb_logger = TensorboardLogger(log_dir=&quot;tb-logger&quot;)
tb_logger.attach_output_handler(
    trainer, event_name=Events.ITERATION_COMPLETED(every=100), tag=&quot;training&quot;,
    output_transform=lambda loss: {&quot;batch_loss&quot;: loss},
)

tb_logger.attach_output_handler(
    evaluator, event_name=Events.EPOCH_COMPLETED,
    tag=&quot;training&quot;, metric_names=&quot;all&quot;,
    global_step_transform=global_step_from_engine(trainer),
)
</code></pre></td></tr></table></section><section><h1 id=distributed-training-support>Distributed Training support</h1><p>Run the same code across all supported backends seamlessly</p><ul><li>Backends from native torch distributed configuration: <code>nccl</code>, <code>gloo</code>, <code>mpi</code></li><li>Horovod framework with <code>gloo</code> or <code>nccl</code> communication backend</li><li>XLA on TPUs via <code>pytorch/xla</code></li></ul><div style=font-size:20px><pre><code class=language-python>import ignite.distributed as idist

def training(local_rank, *args, **kwargs):
    dataloder_train = idist.auto_dataloder(dataset, ...)

    model = ...
    model = idist.auto_model(model)

    optimizer = ...
    optimizer = idist.auto_optimizer(optimizer)

backend = 'nccl'  # or 'gloo', 'horovod', 'xla-tpu' or None
with idist.Parallel(backend) as parallel:
    parallel.run(training)
</code></pre></div></section><section><h1 id=distributed-training-support-1>Distributed Training support</h1><h2 id=distributed-launchers>Distributed launchers</h2><p>Handle distributed launchers with the same code</p><ul><li><code>torch.multiprocessing.spawn</code></li><li><code>torch.distributed.launch</code></li><li><code>horovodrun</code></li><li><code>slurm</code></li></ul></section><section><h1 id=distributed-training-support-2>Distributed Training support</h1><h2 id=unified-distributed-api>Unified Distributed API</h2><ul><li><p>High-level helper methods</p><ul><li><code>idist.auto_model()</code></li><li><code>idist.auto_optim()</code></li><li><code>idist.auto_dataloader()</code></li></ul></li><li><p>Collective operations</p><ul><li><code>all_reduce</code>, <code>all_gather</code>, and more</li></ul></li></ul></section><section><p>Any questions before we go on ?</p></section></section></div><style type=text/css>#footer-left{position:absolute;bottom:0%;left:50%;margin-right:-50%;transform:translate(-50%,-50%)}</style><footer class=footer>PyData Riyadh 2022 Mentored Sprint - 2022/01/14 ‚óã pytorch-ignite.ai</footer></div><script type=text/javascript src=/pydata-riyadh-2022-slides/reveal-hugo/object-assign.js></script><a href=/pydata-riyadh-2022-slides/reveal-js/css/print/ id=print-location style=display:none></a><script type=text/javascript>var printLocationElement=document.getElementById('print-location');var link=document.createElement('link');link.rel='stylesheet';link.type='text/css';link.href=printLocationElement.href+(window.location.search.match(/print-pdf/gi)?'pdf.css':'paper.css');document.getElementsByTagName('head')[0].appendChild(link);</script><script type=application/json id=reveal-hugo-site-params>{"custom_theme":"pytorch-ignite-theme.scss","custom_theme_compile":true,"height":720,"highlight_theme":"monokai-sublime","slide_number":true,"transition_speed":"fast","width":1280}</script><script type=application/json id=reveal-hugo-page-params>null</script><script src=/pydata-riyadh-2022-slides/reveal-js/js/reveal.js></script><script type=text/javascript>function camelize(map){if(map){Object.keys(map).forEach(function(k){newK=k.replace(/(\_\w)/g,function(m){return m[1].toUpperCase()});if(newK!=k){map[newK]=map[k];delete map[k];}});}
return map;}
var revealHugoDefaults={center:true,controls:true,history:true,progress:true,transition:"slide"};var revealHugoSiteParams=JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);var revealHugoPageParams=JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);var options=Object.assign({},camelize(revealHugoDefaults),camelize(revealHugoSiteParams),camelize(revealHugoPageParams));Reveal.initialize(options);</script><script type=text/javascript src=/pydata-riyadh-2022-slides/reveal-js/plugin/markdown/marked.js></script><script type=text/javascript src=/pydata-riyadh-2022-slides/reveal-js/plugin/markdown/markdown.js></script><script type=text/javascript src=/pydata-riyadh-2022-slides/reveal-js/plugin/highlight/highlight.js></script><script type=text/javascript src=/pydata-riyadh-2022-slides/reveal-js/plugin/zoom-js/zoom.js></script><script type=text/javascript src=/pydata-riyadh-2022-slides/reveal-js/plugin/notes/notes.js></script><style>#logo{position:absolute;top:20px;left:20px;width:150px}</style><img id=logo src=https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logomark.svg alt>
<link rel="shortcut icon" href=https://raw.githubusercontent.com/pytorch/ignite/master/assets/logo/ignite_logomark.svg><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css><link rel=stylesheet href=https://rsms.me/inter/inter.css></body></html>